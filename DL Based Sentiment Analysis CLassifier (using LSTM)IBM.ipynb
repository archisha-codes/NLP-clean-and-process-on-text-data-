{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMK5hf+AAQJ8Ns3/ryAsOKU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvIwdukfv7yk","executionInfo":{"status":"ok","timestamp":1763115020325,"user_tz":-330,"elapsed":2888,"user":{"displayName":"Archisha Ranjan","userId":"16724983603333778234"}},"outputId":"a9f4e459-974c-4f71-c24f-40de21e72d16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6667 - loss: 0.6918\n","Epoch 2/10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8333 - loss: 0.6842\n","Epoch 3/10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8333 - loss: 0.6714\n","Epoch 4/10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6667 - loss: 0.6740\n","Epoch 5/10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8333 - loss: 0.6475\n","Epoch 6/10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6667 - loss: 0.6618\n","Epoch 7/10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6667 - loss: 0.6555\n","Epoch 8/10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6667 - loss: 0.6479\n","Epoch 9/10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8333 - loss: 0.5858\n","Epoch 10/10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8333 - loss: 0.5643\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.0000e+00 - loss: 1.0068\n","Test Accuracy: 0.0\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n","Positive Sentiment Probability: 0.35493976\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n","Accuracy: 0.0\n","Precision: 0.0\n","Recall: 0.0\n","Confusion Matrix:\n"," [[0 0]\n"," [2 0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["#Deep Learning Based Sentiment Analysis CLassifier (using LSTM)\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","from sklearn.model_selection import train_test_split\n","# 2. Sample Sentiment Dataset (You can replace with your own)\n","sentences = [\n","    \"I love this movie\",\n","    \"The film was fantastic\",\n","    \"Absolutely wonderful experience\",\n","    \"I hated the movie\",\n","    \"The film was terrible\",\n","    \"Worst experience ever\"\n","]\n","\n","labels = [1, 1, 1, 0, 0, 0]   # 1 = positive, 0 = negative\n","# 3. Tokenization + Convert Text to Sequences\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(sentences)\n","\n","sequences = tokenizer.texts_to_sequences(sentences)\n","padded = pad_sequences(sequences, maxlen=10, padding='post')\n","labels = np.array(labels)\n","\n","\n","# 4. Train-Test Split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    padded, labels, test_size=0.2, random_state=42\n",")\n","\n","# 5. Build the LSTM Model\n","model = Sequential([\n","    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=10),\n","    LSTM(64),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","\n","# 6. Compile the Model\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","\n","# 7. Train the Model\n","model.fit(X_train, y_train, epochs=10, batch_size=2, verbose=1)\n","\n","\n","# 8. Evaluate the Model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"Test Accuracy:\", accuracy)\n","\n","\n","# 9. Test on your own sentences\n","sample = [\"I really loved the film\"]\n","\n","sample_seq = tokenizer.texts_to_sequences(sample)\n","sample_pad = pad_sequences(sample_seq, maxlen=10, padding='post')\n","\n","prediction = model.predict(sample_pad)\n","print(\"Positive Sentiment Probability:\", prediction[0][0])\n","\n","\n","# 10. Detailed Evaluation: Accuracy, Precision, Recall\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n","\n","# Predict on test data\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int)   # Convert probability → class (0/1)\n","\n","# Accuracy\n","acc = accuracy_score(y_test, y_pred)\n","\n","# Precision\n","precision = precision_score(y_test, y_pred)\n","\n","# Recall\n","recall = recall_score(y_test, y_pred)\n","\n","# Confusion Matrix\n","cm = confusion_matrix(y_test, y_pred)\n","\n","print(\"Accuracy:\", acc)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"Confusion Matrix:\\n\", cm)\n"]}]}